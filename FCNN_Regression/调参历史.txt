调节神经网络的超参数是一件十分重要又十分繁琐的工作，如果超参数调整不当，则网络的性能将会受到十分的负面影响，以下将给出指引。
1. 首先利用测试集的准确率去判断超参数的合理性，观察往哪个方向，或哪个趋势调整超参数时，测试集准确率会有提升。
2. 不断按好的趋势调整超参数，直至测试集的准确率达到满意为止。
3. 为了正确衡量网络的真实性能，防止网络把超参数也拟合进去，验证集应被测试一次且在一个调整阶段只能被测试一次。
4. 可以先对参数的量级进行调整，再微调参数。
5. 可以先调学习率，再调规范化参数。
6. 更为合理、科学的调参程序将会在后续版本中给出。
7. 更多信息请参阅”截取_如何调整网络的超参数.pdf“

以下是针对不同分类问题的一些超参数的推荐值。

% 参数名解释
% epochs 训练次数
% mini_batch_size 小批量大小
% eta 学习率
% lmbda L型规范化参数
% net_inner_sizes 隐藏层，"[]"表示无隐藏层
% reg_fun 规范化函数

% 1nm，自来水，怡宝，农夫山泉三分类
% epochs = 500;
% mini_batch_size  = 10;
% eta = 0.12;
% lmbda = 0.015;
% net_inner_sizes = [];
% reg_fun = "L1";

% epochs = 2000;
% mini_batch_size  = 10;
% eta = 0.03;
% lmbda = 0.015;
% net_inner_sizes = [];
% reg_fun = "L1";


% 10nm，自来水，怡宝，农夫山泉三分类
% epochs = 500;
% mini_batch_size  = 10;
% eta = 0.12;
% lmbda = 0.02;
% net_inner_sizes = [30];
% reg_fun = "L2";

% 1nm，怡宝，农夫山泉二分类（二分类问题的训练次数可适当再增加一些，而学习率应适当减少一些）
% epochs = 700;
% mini_batch_size  = 10;
% eta = 0.03;
% lmbda = 0.08;
% net_inner_sizes = []; (or 100)
% reg_fun = "L1";(or "L2")

% 1nm，怡宝，农夫山泉二分类（二分类问题的训练次数可适当再增加一些，而学习率应适当减少一些）
% epochs = 700;
% mini_batch_size  = 10;
% eta = 0.03;
% lmbda = 0.08;
% net_inner_sizes = []; (or 100)
% reg_fun = "L1";(or "L2")

% 1nm，怡宝，农夫山泉二分类（二分类问题的训练次数可适当再增加一些，而学习率应适当减少一些）
% epochs = 700;
% mini_batch_size  = 10;
% eta = 0.03;
% lmbda = 0.08;
% net_inner_sizes = []; (or 100)
% reg_fun = "L1";(or "L2")